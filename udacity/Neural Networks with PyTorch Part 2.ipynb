{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#normalizamos los datos\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3169, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Contruimos el feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10))\n",
    "\n",
    "#Definimos la perdida, loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Obtenemos nuestros datos\n",
    "images,labels = next(iter(trainloader))\n",
    "\n",
    "#Flatten\n",
    "images = images.view(images.shape[0],-1)\n",
    "logits = model(images)\n",
    "loss = criterion(logits,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3334, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "# cambiamos a NLLLoss\n",
    "criterion= nn.NLLLoss()\n",
    "images,labels = next(iter(trainloader))\n",
    "images=images.view(images.shape[0],-1)\n",
    "\n",
    "logps=model(images) #log probabilities\n",
    "loss=criterion(logps,labels)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Autograd\n",
    "Calcula las gradientes que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "x = torch.zeros(1,requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1355,  1.2524],\n",
      "        [-1.0700,  1.7596]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo 2\n",
    "x = torch.randn(2,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2893, 1.5686],\n",
       "        [1.1450, 3.0961]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x11fa8b110>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn) #tiene un historial, donde el pow (potencia) quedo grabado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7747, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5677,  0.6262],\n",
      "        [-0.5350,  0.8798]])\n",
      "tensor([[ 0.5677,  0.6262],\n",
      "        [-0.5350,  0.8798]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5914, -1.0873]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 3\n",
    "x = torch.randn(1,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3498, 1.1822]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PowBackward0 at 0x11cacd210>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5320, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1829, -2.1746]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1829, -2.1746]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(2*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loss and Autograd together\n",
    "Calcularemos el loss, las gradientes para los parametros seran calculados. Estas gradientes seran usadas para actualizar los pesos de la gradiente descendiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images,labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0],-1) #flatten\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass:  None\n",
      "Before backward pass:  tensor([[-0.0017, -0.0017, -0.0017,  ..., -0.0017, -0.0017, -0.0017],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        ...,\n",
      "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
      "        [ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: ',model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('Before backward pass: ',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "Necesitamos de un optimizador que usaremos para actualizar los pesos con las gradientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de entrenamiento sera el siguiente:\n",
    "* Hacemos un forward a traves de la red neuronal\n",
    "* Usamos la salida de la red neuronal para calcular el loss\n",
    "* Realizamos un pase backward a traves de la red con loss.backward() para calcular las gradientes\n",
    "* Tomamos un paso con el optimizador para actualizar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights-  Parameter containing:\n",
      "tensor([[ 0.0271,  0.0329, -0.0057,  ..., -0.0102, -0.0281, -0.0058],\n",
      "        [ 0.0160,  0.0048,  0.0089,  ..., -0.0353,  0.0309, -0.0213],\n",
      "        [ 0.0274, -0.0134, -0.0219,  ..., -0.0146, -0.0274,  0.0077],\n",
      "        ...,\n",
      "        [ 0.0042, -0.0038, -0.0111,  ..., -0.0310, -0.0030,  0.0323],\n",
      "        [-0.0318,  0.0248, -0.0094,  ..., -0.0229,  0.0339, -0.0311],\n",
      "        [-0.0002,  0.0034, -0.0283,  ..., -0.0265,  0.0188,  0.0024]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-1.8466e-03, -1.8466e-03, -1.8466e-03,  ..., -1.8466e-03,\n",
      "         -1.8466e-03, -1.8466e-03],\n",
      "        [-9.1986e-05, -9.1986e-05, -9.1986e-05,  ..., -9.1986e-05,\n",
      "         -9.1986e-05, -9.1986e-05],\n",
      "        [ 3.6501e-04,  3.6501e-04,  3.6501e-04,  ...,  3.6501e-04,\n",
      "          3.6501e-04,  3.6501e-04],\n",
      "        ...,\n",
      "        [ 8.8283e-04,  8.8283e-04,  8.8283e-04,  ...,  8.8283e-04,\n",
      "          8.8283e-04,  8.8283e-04],\n",
      "        [-9.4582e-04, -9.4582e-04, -9.4582e-04,  ..., -9.4582e-04,\n",
      "         -9.4582e-04, -9.4582e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights- ',model[0].weight)\n",
    "\n",
    "images,labels = next(iter(trainloader))\n",
    "images.resize_(64,784)\n",
    "\n",
    "#Limpiamos las gradientes, hacemos esto para no acumularlo\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Hacemos un pase forward, \n",
    "output=model.forward(images)\n",
    "loss=criterion(output,labels)\n",
    "#despues un backward, para finalizar actualizando los pesos\n",
    "loss.backward()\n",
    "print('Gradient -',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig loss: 1.8999119041316799\n",
      "Trainig loss: 0.8732810502748753\n",
      "Trainig loss: 0.5519429882134456\n",
      "Trainig loss: 0.4449124358324354\n",
      "Trainig loss: 0.39336270432291764\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #hacemos plano la imagen, a un vector  de 784\n",
    "        images=images.view(images.shape[0],-1)\n",
    "        #training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        print('Trainig loss: {}'.format(running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Copia de UDACITY:\n",
    "'''\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import helper\n",
    "images, labels = next(iter(trainloader))\n",
    "img = images[0].view(1,784)\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "ps = F.softmax(logits,dim=1)\n",
    "view_classify(img.view(1,28,28),ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
