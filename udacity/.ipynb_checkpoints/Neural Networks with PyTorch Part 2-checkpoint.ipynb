{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#normalizamos los datos\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3169, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Contruimos el feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10))\n",
    "\n",
    "#Definimos la perdida, loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Obtenemos nuestros datos\n",
    "images,labels = next(iter(trainloader))\n",
    "\n",
    "#Flatten\n",
    "images = images.view(images.shape[0],-1)\n",
    "logits = model(images)\n",
    "loss = criterion(logits,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3334, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "# cambiamos a NLLLoss\n",
    "criterion= nn.NLLLoss()\n",
    "images,labels = next(iter(trainloader))\n",
    "images=images.view(images.shape[0],-1)\n",
    "\n",
    "logps=model(images) #log probabilities\n",
    "loss=criterion(logps,labels)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Autograd\n",
    "Calcula las gradientes que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "x = torch.zeros(1,requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1355,  1.2524],\n",
      "        [-1.0700,  1.7596]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo 2\n",
    "x = torch.randn(2,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2893, 1.5686],\n",
       "        [1.1450, 3.0961]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x11fa8b110>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn) #tiene un historial, donde el pow (potencia) quedo grabado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7747, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5677,  0.6262],\n",
      "        [-0.5350,  0.8798]])\n",
      "tensor([[ 0.5677,  0.6262],\n",
      "        [-0.5350,  0.8798]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5914, -1.0873]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 3\n",
    "x = torch.randn(1,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3498, 1.1822]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PowBackward0 at 0x11cacd210>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5320, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1829, -2.1746]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1829, -2.1746]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(2*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loss and Autograd together\n",
    "Calcularemos el loss, las gradientes para los parametros seran calculados. Estas gradientes seran usadas para actualizar los pesos de la gradiente descendiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images,labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0],-1) #flatten\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass:  None\n",
      "Before backward pass:  tensor([[-0.0017, -0.0017, -0.0017,  ..., -0.0017, -0.0017, -0.0017],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        ...,\n",
      "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
      "        [ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: ',model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('Before backward pass: ',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "Necesitamos de un optimizador que usaremos para actualizar los pesos con las gradientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de entrenamiento sera el siguiente:\n",
    "* Hacemos un forward a traves de la red neuronal\n",
    "* Usamos la salida de la red neuronal para calcular el loss\n",
    "* Realizamos un pase backward a traves de la red con loss.backward() para calcular las gradientes\n",
    "* Tomamos un paso con el optimizador para actualizar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights-  Parameter containing:\n",
      "tensor([[ 0.0271,  0.0329, -0.0057,  ..., -0.0102, -0.0281, -0.0058],\n",
      "        [ 0.0160,  0.0048,  0.0089,  ..., -0.0353,  0.0309, -0.0213],\n",
      "        [ 0.0274, -0.0134, -0.0219,  ..., -0.0146, -0.0274,  0.0077],\n",
      "        ...,\n",
      "        [ 0.0042, -0.0038, -0.0111,  ..., -0.0310, -0.0030,  0.0323],\n",
      "        [-0.0318,  0.0248, -0.0094,  ..., -0.0229,  0.0339, -0.0311],\n",
      "        [-0.0002,  0.0034, -0.0283,  ..., -0.0265,  0.0188,  0.0024]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-1.8466e-03, -1.8466e-03, -1.8466e-03,  ..., -1.8466e-03,\n",
      "         -1.8466e-03, -1.8466e-03],\n",
      "        [-9.1986e-05, -9.1986e-05, -9.1986e-05,  ..., -9.1986e-05,\n",
      "         -9.1986e-05, -9.1986e-05],\n",
      "        [ 3.6501e-04,  3.6501e-04,  3.6501e-04,  ...,  3.6501e-04,\n",
      "          3.6501e-04,  3.6501e-04],\n",
      "        ...,\n",
      "        [ 8.8283e-04,  8.8283e-04,  8.8283e-04,  ...,  8.8283e-04,\n",
      "          8.8283e-04,  8.8283e-04],\n",
      "        [-9.4582e-04, -9.4582e-04, -9.4582e-04,  ..., -9.4582e-04,\n",
      "         -9.4582e-04, -9.4582e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights- ',model[0].weight)\n",
    "\n",
    "images,labels = next(iter(trainloader))\n",
    "images.resize_(64,784)\n",
    "\n",
    "#Limpiamos las gradientes, hacemos esto para no acumularlo\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Hacemos un pase forward, \n",
    "output=model.forward(images)\n",
    "loss=criterion(output,labels)\n",
    "#despues un backward, para finalizar actualizando los pesos\n",
    "loss.backward()\n",
    "print('Gradient -',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
